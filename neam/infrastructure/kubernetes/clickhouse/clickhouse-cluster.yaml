# ClickHouse Analytics Cluster
# 2 shards, 2 replicas for high availability and horizontal scaling

apiVersion: v1
kind: Namespace
metadata:
  name: neam-analytics
  labels:
    app.kubernetes.io/name: neam-platform
    app.kubernetes.io/component: analytics
    app.kubernetes.io/part-of: neam

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: clickhouse-config
  namespace: neam-analytics
  labels:
    app.kubernetes.io/name: neam-clickhouse
data:
  config.xml: |
    <?xml version="1.0"?>
    <clickhouse>
      <logger>
        <level>information</level>
        <console>true</console>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</log>
        <size>1000M</size>
        <count>10</count>
      </logger>

      <listen_host>0.0.0.0</listen_host>
      <http_port>8123</http_port>
      <tcp_port>9000</tcp_port>
      <interserver_http_port>9009</interserver_http_port>

      <max_concurrent_queries>1000</max_concurrent_queries>
      <max_connections>10000</max_connections>
      <keep_alive_timeout>300</keep_alive_timeout>

      <uncompressed_cache_size>5368709120</uncompressed_cache_size>
      <mark_cache_size>5368709120</mark_cache_size>

      <path>/var/lib/clickhouse/</path>
      <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
      <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>

      <users_config>users.xml</users_config>
      <default_profile>default</default_profile>
      <default_database>default</default_database>

      <distributed_ddl>
        <path>/clickhouse/distributed_ddl</path>
      </distributed_ddl>

      <include_from>/etc/clickhouse-operator/conf.d/*.xml</include_from>
    </clickhouse>

  users.xml: |
    <?xml version="1.0"?>
    <clickhouse>
      <users>
        <neam_admin>
          <password>${CLICKHOUSE_PASSWORD}</password>
          <profile>default</profile>
          <quota>default</quota>
          <databases>
            <neam_analytics>
              <tables>
                <*>rw</tables>
              </databases>
            </neam_analytics>
          </databases>
          <allow_databases>
            <neam_analytics>neam_admin</neam_analytics>
          </allow_databases>
        </neam_admin>

        <readonly>
          <password>${READONLY_PASSWORD}</password>
          <profile>readonly</profile>
          <quota>readonly</quota>
        </readonly>

        <neam_dashboard>
          <password>${DASHBOARD_PASSWORD}</password>
          <profile>dashboard</profile>
          <quota>dashboard</quota>
          <databases>
            <neam_analytics>
              <tables>
                <*.inner.*>rw</tables>
              </databases>
            </neam_analytics>
          </databases>
        </neam_dashboard>
      </users>

      <profiles>
        <default>
          <max_memory_usage>10737418240</max_memory_usage>
          <max_query_size>262144</max_query_size>
          <max_ast_elements>50000</max_ast_elements>
          <max_execution_time>60</max_execution_time>
          <receive_timeout>10</receive_timeout>
          <send_timeout>300</send_timeout>
        </default>

        <readonly>
          <max_memory_usage>10737418240</max_memory_usage>
          <readonly>1</readonly>
        </readonly>

        <dashboard>
          <max_memory_usage>10737418240</max_memory_usage>
          <max_execution_time>30</max_execution_time>
          <max_result_rows>1000000</max_result_rows>
        </dashboard>
      </profiles>

      <quotas>
        <default>
          <interval>
            <duration>3600</duration>
            <queries>0</queries>
            <errors>0</queries>
            <result_rows>0</queries>
            <read_rows>0</queries>
            <execution_time>0</execution_time>
          </interval>
        </default>

        <readonly>
          <interval>
            <duration>3600</duration>
            <queries>1000</queries>
            <errors>10</errors>
            <result_rows>10000000</result_rows>
            <read_rows>100000000</read_rows>
            <execution_time>3600</execution_time>
          </interval>
        </readonly>

        <dashboard>
          <interval>
            <duration>3600</duration>
            <queries>10000</queries>
            <errors>100</errors>
            <result_rows>100000000</result_rows>
            <read_rows>1000000000</read_rows>
            <execution_time>3600</execution_time>
          </interval>
        </dashboard>
      </quotas>
    </clickhouse>

---
apiVersion: clickhouse.altinity.com/v1
kind: ClickHouseInstallation
metadata:
  name: neam-clickhouse
  namespace: neam-analytics
  labels:
    app.kubernetes.io/name: neam-clickhouse
    app.kubernetes.io/instance: neam
    app.kubernetes.io/component: analytics
    app.kubernetes.io/part-of: neam
spec:
  # 4 nodes: 2 shards with 2 replicas each
  configuration:
    clusters:
      - name: neam-cluster
        shards:
          - name: shard1
            replicasCount: 2
            templates:
              volumeClaimTemplate: data-volume
          - name: shard2
            replicasCount: 2
            templates:
              volumeClaimTemplate: data-volume

    zookeeper:
      hosts:
        - clickhouse-keeper.neam-analytics:2181
      sessionTimeoutMs: 30000
      connectionTimeoutMs: 10000

    settings:
      # Performance tuning
      max_thread_pool_size: 200
      thread_pool_queue_size: 500
      max_concurrent_queries: 1000
      memory_usage_limit_ratio: 0.9
      background_pool_size: 16
      background_schedule_pool_size: 16
      background_move_pool_size: 8

      # Merge tree settings
      max_merge_list_size: 100000
      merge_tree_max_rows_to_use_cache: 10485760

      # Distributed settings
      distributed_replication_queue_max_size: 1000000
      distributed_directory_monitor_batch_inserts: 1

      # Compression
      min_compress_block_size: 65536
      max_compress_block_size: 1048576

    # Remote servers configuration (auto-generated)
    remoteServers:
      auto:
        <remote_servers>
          <neam_cluster>
            <shard>
              <internal_replication>true</internal_replication>
              <replica>
                <host>neam-clickhouse-neam-clickhouse-0-0</host>
                <port>9000</port>
              </replica>
              <replica>
                <host>neam-clickhouse-neam-clickhouse-0-1</host>
                <port>9000</port>
              </replica>
            </shard>
            <shard>
              <internal_replication>true</internal_replication>
              <replica>
                <host>neam-clickhouse-neam-clickhouse-1-0</host>
                <port>9000</port>
              </replica>
              <replica>
                <host>neam-clickhouse-neam-clickhouse-1-1</host>
                <port>9000</port>
              </replica>
            </shard>
          </neam_cluster>
        </remote_servers>

    users:
      neam_admin/password: ${CLICKHOUSE_ADMIN_PASSWORD}
      readonly/password: ${CLICKHOUSE_READONLY_PASSWORD}
      neam_dashboard/password: ${CLICKHOUSE_DASHBOARD_PASSWORD}

    databases:
      - name: neam_analytics
        # Replicated database for HA
        engine:
          name: Replicated
          parameters:
            database_name: neam_analytics
            zoo_path: /clickhouse/neam_analytics

  # Storage configuration
  templates:
    volumeClaimTemplate:
      name: data-volume
      spec:
        storageClassName: nvme-ssd
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 200Gi

  # Pod configuration
  pod:
    resources:
      requests:
        cpu: "4"
        memory: "16Gi"
      limits:
        cpu: "8"
        memory: "32Gi"

    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/name: neam-clickhouse
            topologyKey: kubernetes.io/hostname

    securityContext:
      runAsNonRoot: true
      runAsUser: 999
      runAsGroup: 999
      fsGroup: 999
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true

    tolerations:
      - key: "database"
        operator: "Equal"
        value: "analytics"
        effect: "NoSchedule"

  # Service configuration
  service:
    type: ClusterIP
    annotations: {}

---
apiVersion: v1
kind: Service
metadata:
  name: neam-clickhouse
  namespace: neam-analytics
  labels:
    app.kubernetes.io/name: neam-clickhouse
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8123
      targetPort: http
    - name: tcp
      port: 9000
      targetPort: tcp
  selector:
    clickhouse.altinity.com/namespace: neam-analytics
    clickhouse.altinity.com/chi: neam-clickhouse

---
apiVersion: v1
kind: Service
metadata:
  name: neam-clickhouse-query
  namespace: neam-analytics
  labels:
    app.kubernetes.io/name: neam-clickhouse
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8123
      targetPort: http
  selector:
    clickhouse.altinity.com/namespace: neam-analytics
    clickhouse.altinity.com/chi: neam-clickhouse
    clickhouse.altinity.com/replica: "false"

---
# ClickHouse Keeper (ZooKeeper replacement)
apiVersion: v1
kind: StatefulSet
metadata:
  name: clickhouse-keeper
  namespace: neam-analytics
spec:
  serviceName: clickhouse-keeper
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: clickhouse-keeper
  template:
    metadata:
      labels:
        app.kubernetes.io/name: clickhouse-keeper
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app.kubernetes.io/name: clickhouse-keeper
              topologyKey: kubernetes.io/hostname
      containers:
        - name: keeper
          image: clickhouse/keeper:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 2181
              name: client
            - containerPort: 9000
              name: server
            - containerPort: 8080
              name: http
          env:
            - name: KEEPER_LOG_DIR
              value: /var/lib/keeper/log
            - name: KEEPER_DATA_DIR
              value: /var/lib/keeper/data
          resources:
            requests:
              cpu: "500m"
              memory: "1Gi"
            limits:
              cpu: "2"
              memory: "2Gi"
          volumeMounts:
            - name: data
              mountPath: /var/lib/keeper
            - name: log
              mountPath: /var/lib/keeper/log
      volumes:
        - name: log
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        storageClassName: nvme-ssd
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi

---
apiVersion: v1
kind: Service
metadata:
  name: clickhouse-keeper
  namespace: neam-analytics
  labels:
    app.kubernetes.io/name: clickhouse-keeper
spec:
  clusterIP: None
  ports:
    - name: client
      port: 2181
    - name: server
      port: 9000
    - name: http
      port: 8080
  selector:
    app.kubernetes.io/name: clickhouse-keeper

---
# Network Policy
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: clickhouse-network-policy
  namespace: neam-analytics
spec:
  podSelector:
    matchLabels:
      clickhouse.altinity.com/namespace: neam-analytics
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: neam
        - namespaceSelector:
            matchLabels:
              name: neam-analytics
      ports:
        - protocol: TCP
          port: 8123
        - protocol: TCP
          port: 9000
  egress:
    - to:
        - podSelector:
            matchLabels:
              k8s-app: kube-dns
      ports:
        - protocol: UDP
          port: 53
